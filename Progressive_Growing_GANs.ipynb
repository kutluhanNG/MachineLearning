{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPvjZKcqjP89PRTasLmPsOz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kutluhanNG/MachineLearning/blob/main/Progressive_Growing_GANs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Utility Layers:**\n",
        "* PixelNormalization scales features at each pixel to unit norm.\n",
        "* MinibatchStdDev computes a simple statistic over the batch and appends it as an extra feature map.\n",
        "* upsample and downsample functions change the spatial resolution."
      ],
      "metadata": {
        "id": "qhbsx6FbLlBu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TYmVOVJhALpz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# ---------------------------\n",
        "# Utility Layers and Functions\n",
        "# ---------------------------\n",
        "\n",
        "class PixelNormalization(layers.Layer):\n",
        "    \"\"\"\n",
        "    Normalizes each pixel vector (across channels) to unit length.\n",
        "    \"\"\"\n",
        "    def __init__(self, epsilon=1e-8, **kwargs):\n",
        "        super(PixelNormalization, self).__init__(**kwargs)\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return inputs / tf.sqrt(tf.reduce_mean(tf.square(inputs), axis=-1, keepdims=True) + self.epsilon)\n",
        "\n",
        "\n",
        "class MinibatchStdDev(layers.Layer):\n",
        "    \"\"\"\n",
        "    Adds a minibatch standard deviation feature map.\n",
        "    \"\"\"\n",
        "    def call(self, inputs):\n",
        "        # Compute standard deviation over the batch\n",
        "        mean = tf.reduce_mean(inputs, axis=0, keepdims=True)\n",
        "        std = tf.sqrt(tf.reduce_mean(tf.square(inputs - mean), axis=0, keepdims=True) + 1e-8)\n",
        "        mean_std = tf.reduce_mean(std, keepdims=True)\n",
        "        shape = tf.shape(inputs)\n",
        "\n",
        "        # Tile to have one extra channel\n",
        "        output = tf.tile(mean_std, [shape[0], shape[1], shape[2], 1])\n",
        "        return tf.concat([inputs, output], axis=-1)\n",
        "\n",
        "\n",
        "def upsample(x):\n",
        "    \"\"\"Upsamples feature maps by a factor of 2 using nearest neighbor.\"\"\"\n",
        "    new_size = (x.shape[1] * 2, x.shape[2] * 2)\n",
        "    return tf.image.resize(x, new_size, method='nearest')\n",
        "\n",
        "\n",
        "def downsample(x):\n",
        "    \"\"\"Downsamples feature maps by a factor of 2 using average pooling.\"\"\"\n",
        "    return tf.nn.avg_pool2d(x, ksize=2, strides=2, padding='SAME')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generator:**\n",
        "* The generator starts by mapping a latent vector to a 4×4 feature map.\n",
        "* It then passes through a series of blocks; each new block is “faded in” using the parameter alpha so that when transitioning to a higher resolution, the output is a blend of the new (higher‐resolution) branch and the upsampled previous branch.\n",
        "* The final “to_rgb” convolution converts feature maps to a three–channel image."
      ],
      "metadata": {
        "id": "j2qHXSktL3sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Progressive Generator\n",
        "# ---------------------------\n",
        "\n",
        "class ProgressiveGenerator(tf.keras.Model):\n",
        "    def __init__(self, latent_dim, num_steps=4, **kwargs):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            latent_dim: Dimension of the latent input vector.\n",
        "            num_steps: Number of progressive steps. Step 0 produces 4×4 images,\n",
        "                       step 1 produces 8×8, step 2 produces 16×16, etc.\n",
        "        \"\"\"\n",
        "        super(ProgressiveGenerator, self).__init__(**kwargs)\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_steps = num_steps  # e.g. 4 steps: 4x4, 8x8, 16x16, 32x32\n",
        "\n",
        "        # Initial dense layer to project the latent vector to a 4x4 feature map.\n",
        "        self.initial_dense = layers.Dense(4 * 4 * 512, input_shape=(latent_dim,))\n",
        "        self.initial_reshape = layers.Reshape((4, 4, 512))\n",
        "        self.pixel_norm = PixelNormalization()\n",
        "\n",
        "        # Lists to hold the convolutional blocks and corresponding \"to-RGB\" layers.\n",
        "        self.blocks = []    # Each block increases the resolution.\n",
        "        self.to_rgb = []    # Converts feature maps to RGB images.\n",
        "\n",
        "        # --- Block for 4×4 resolution ---\n",
        "        block0 = tf.keras.Sequential([\n",
        "            layers.Conv2D(512, kernel_size=3, padding='same'),\n",
        "            layers.LeakyReLU(0.2),\n",
        "            PixelNormalization()\n",
        "        ])\n",
        "        self.blocks.append(block0)\n",
        "        self.to_rgb.append(layers.Conv2D(3, kernel_size=1, padding='same', activation='tanh'))\n",
        "\n",
        "        # --- Progressive blocks: each block doubles the resolution ---\n",
        "        # You can adjust the filter sizes as desired.\n",
        "        filters = [512, 256, 128, 64]  # For steps 1, 2, 3, … (must be at least num_steps-1 elements)\n",
        "        for i in range(1, self.num_steps):\n",
        "            block = tf.keras.Sequential([\n",
        "                layers.Conv2D(filters[i], kernel_size=3, padding='same'),\n",
        "                layers.LeakyReLU(0.2),\n",
        "                PixelNormalization(),\n",
        "                layers.Conv2D(filters[i], kernel_size=3, padding='same'),\n",
        "                layers.LeakyReLU(0.2),\n",
        "                PixelNormalization()\n",
        "            ])\n",
        "            self.blocks.append(block)\n",
        "            self.to_rgb.append(layers.Conv2D(3, kernel_size=1, padding='same', activation='tanh'))\n",
        "\n",
        "    def call(self, inputs, alpha, step):\n",
        "        \"\"\"\n",
        "        Forward pass.\n",
        "\n",
        "        Args:\n",
        "            inputs: A batch of latent vectors, shape (batch_size, latent_dim).\n",
        "            alpha: Fade-in factor (0.0 to 1.0). When alpha < 1.0, the new block is gradually blended in.\n",
        "            step: Current progressive step (integer). 0 means the base 4×4 resolution.\n",
        "\n",
        "        Returns:\n",
        "            Generated images.\n",
        "        \"\"\"\n",
        "        # Start from the latent vector.\n",
        "        x = self.initial_dense(inputs)\n",
        "        x = self.initial_reshape(x)\n",
        "        x = self.pixel_norm(x)\n",
        "        # Process through the initial block (4×4)\n",
        "        x = self.blocks[0](x)\n",
        "\n",
        "        # If no progression yet, output the 4×4 image.\n",
        "        if step == 0:\n",
        "            rgb = self.to_rgb[0](x)\n",
        "            return rgb\n",
        "\n",
        "        # Process all intermediate blocks before the current (new) one.\n",
        "        for i in range(1, step):\n",
        "            x = upsample(x)\n",
        "            x = self.blocks[i](x)\n",
        "\n",
        "        # For the current step: upsample then use two branches for fade-in.\n",
        "        x_up = upsample(x)  # Upsample to the new resolution.\n",
        "        # New branch: apply the new block.\n",
        "        x_new = self.blocks[step](x_up)\n",
        "        rgb_new = self.to_rgb[step](x_new)\n",
        "        # Old branch: use the previous block’s to-RGB (applied to the upsampled features).\n",
        "        rgb_old = self.to_rgb[step - 1](x_up)\n",
        "        # Blend the two outputs.\n",
        "        rgb = alpha * rgb_new + (1.0 - alpha) * rgb_old\n",
        "        return rgb"
      ],
      "metadata": {
        "id": "PUYXAOtQL4GA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discriminator:**\n",
        "* The discriminator works in the reverse order. It converts an input image (at the current resolution) to features using a “from_rgb” layer.\n",
        "* When a new block is added, it blends the features from the current resolution with features from a downsampled (previous resolution) branch.\n",
        "* Finally, several convolutional blocks and a final dense layer produce a real/fake score."
      ],
      "metadata": {
        "id": "p9_-wTdnMILV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ProgressiveDiscriminator(tf.keras.Model):\n",
        "    def __init__(self, num_steps=4, **kwargs):\n",
        "        super(ProgressiveDiscriminator, self).__init__(**kwargs)\n",
        "        self.num_steps = num_steps\n",
        "\n",
        "        # Use a fixed number of channels for all from-RGB layers for blending\n",
        "        from_rgb_filters = 512\n",
        "        self.from_rgb = []\n",
        "        for i in range(self.num_steps):\n",
        "            self.from_rgb.append(tf.keras.Sequential([\n",
        "                layers.Conv2D(from_rgb_filters, kernel_size=1, padding='same'),\n",
        "                layers.LeakyReLU(0.2)\n",
        "            ]))\n",
        "\n",
        "        # Build convolutional blocks (you can still use a descending filter schedule here)\n",
        "        filters = [512, 512, 256, 128, 64]  # Adjust as needed\n",
        "        self.blocks = []\n",
        "        for i in range(self.num_steps - 1, 0, -1):\n",
        "            block = tf.keras.Sequential([\n",
        "                layers.Conv2D(filters[i], kernel_size=3, padding='same'),\n",
        "                layers.LeakyReLU(0.2),\n",
        "                layers.Conv2D(filters[i - 1], kernel_size=3, padding='same'),\n",
        "                layers.LeakyReLU(0.2)\n",
        "            ])\n",
        "            self.blocks.append(block)\n",
        "\n",
        "        self.final_block = tf.keras.Sequential([\n",
        "            MinibatchStdDev(),\n",
        "            layers.Conv2D(512, kernel_size=3, padding='same'),\n",
        "            layers.LeakyReLU(0.2),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(1)\n",
        "        ])\n",
        "\n",
        "    def call(self, inputs, alpha, step):\n",
        "        if step == 0:\n",
        "            x = self.from_rgb[0](inputs)\n",
        "            x = self.final_block(x)\n",
        "            return x\n",
        "\n",
        "        # New branch: process the current resolution.\n",
        "        x_new = self.from_rgb[step](inputs)\n",
        "        # Downsample the new branch so that its spatial size matches the old branch.\n",
        "        x_new = downsample(x_new)\n",
        "\n",
        "        # Old branch: downsample the input first, then process with the previous from-RGB layer.\n",
        "        x_old = self.from_rgb[step - 1](downsample(inputs))\n",
        "\n",
        "        # Now both x_new and x_old should have the same shape: (batch, new_H, new_W, 512)\n",
        "        x = alpha * x_new + (1.0 - alpha) * x_old\n",
        "\n",
        "        # Process the blended features through the progressive blocks.\n",
        "        start = self.num_steps - 1 - step\n",
        "        for block in self.blocks[start:]:\n",
        "            x = block(x)\n",
        "            x = downsample(x)\n",
        "\n",
        "        x = self.final_block(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "-jfaFmoOMQ4g"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example Usage:**\n",
        "* In the main block, a generator and discriminator are instantiated.\n",
        "* A batch of random latent vectors is generated and passed through the generator (using a specified alpha and step).\n",
        "* The generated images are then passed through the discriminator."
      ],
      "metadata": {
        "id": "lks2szLSMWxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Example Usage\n",
        "# ---------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Define latent dimension and number of progression steps.\n",
        "    latent_dim = 128\n",
        "    num_steps = 4  # For example, step 0: 4×4, step 1: 8×8, step 2: 16×16, step 3: 32×32\n",
        "\n",
        "    # Instantiate the generator and discriminator.\n",
        "    generator = ProgressiveGenerator(latent_dim, num_steps)\n",
        "    discriminator = ProgressiveDiscriminator(num_steps)\n",
        "\n",
        "    # Create a random batch of latent vectors.\n",
        "    z = tf.random.normal((4, latent_dim))\n",
        "\n",
        "    # Set the fade-in factor (alpha) and the current progressive step.\n",
        "    alpha = 0.5  # During fade-in, alpha moves gradually from 0 to 1.\n",
        "    step = 2     # For example, step 2 corresponds to a 16×16 resolution output.\n",
        "\n",
        "    # Generate images.\n",
        "    fake_images = generator(z, alpha=alpha, step=step)\n",
        "    print(\"Generated images shape:\", fake_images.shape)\n",
        "\n",
        "    # Get the discriminator's output on the generated images.\n",
        "    d_out = discriminator(fake_images, alpha=alpha, step=step)\n",
        "    print(\"Discriminator output shape:\", d_out.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEGSDiV_M8W2",
        "outputId": "2d34f675-5c3f-475e-b97c-318e5161ef1e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'progressive_generator_5', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated images shape: (4, 16, 16, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'progressive_discriminator_5', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator output shape: (4, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming fake_images is the output from the generator.\n",
        "# The generated images are likely in the range [-1, 1] due to the tanh activation.\n",
        "# Rescale them to [0, 1] for visualization.\n",
        "def rescale_img(img):\n",
        "    img = (img + 1.0) / 2.0  # Scale from [-1, 1] to [0, 1]\n",
        "    # Clip in case any values fall slightly outside due to numerical issues.\n",
        "    return np.clip(img, 0, 1)\n",
        "\n",
        "# Convert the tensor to a numpy array.\n",
        "fake_images_np = fake_images.numpy()\n",
        "\n",
        "# Plot each image in the batch.\n",
        "batch_size = fake_images_np.shape[0]\n",
        "plt.figure(figsize=(batch_size * 3, 3))\n",
        "for i in range(batch_size):\n",
        "    plt.subplot(1, batch_size, i + 1)\n",
        "    # Rescale the image for display.\n",
        "    img = rescale_img(fake_images_np[i])\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "mvJeZoUDNWsx",
        "outputId": "e652aadc-4bd9-4f89-888c-1da7dcb54904"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x300 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sciwy0b4PKDj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}